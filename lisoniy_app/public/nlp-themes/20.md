# 20-Mavzu: Mahalliy LLMlar

## Sizning Shaxsiy va Maxfiy Sun'iy Intellektingiz

Agar loyihangiz uchun maxfiylik birinchi o'rinda bo'lsa yoki API to'lovlaridan qochmoqchi bo'lsangiz, yechim bor — **Mahalliy (Local) LLMlar.** Bugungi kunda Llama 3, Mistral va Gemma kabi ochiq manbali modellar kuchi bo'yicha hatto GPT-4 ga ham ancha yaqinlashib qolgan va ularni oddiy kompyuterda ishga tushirish mumkin.

---

### Nima Uchun Mahalliy LLMni Tanlash Kerak?

1.  **To'liq Maxfiylik:** Ma'lumotlaringiz kompyuteringizdan tashqariga chiqmaydi. Bu davlat idoralari yoki shaxsiy ma'lumotlar bilan ishlashda o'ta muhim.
2.  **Cheksiz Foydalanish:** Tokenlar uchun pul to'lamaysiz. GPU quvvati yetsa, 24/7 bepul ishlatish mumkin.
3.  **Offline Ishlash:** Internet ulanishi shart emas.
4.  **Tahrirlash Imkoniyati (Fine-tuning):** Siz ochiq modellar kodini o'zgartirishingiz va ularni faqat o'zbek tiliga yoki o'z sohangizga moslab qayta o'qitishingiz mumkin.

---

### Eng Yaxshi Ochiq Manba Modellari

-   **Meta Llama 3:** Hozirda eng mashhur va universal ochiq model. 8B (kichik) va 70B (katta) versiyalari mavjud.
-   **Mistral / Mixtral:** Frantsiyadan kelgan model, juda samarador va tezkor.
-   **DeepSeek:** Kod yozish bo'yicha eng kuchli ochiq modellardan biri.

---

### Mahalliy LLMni Qanday Ishga Tushirish Mumkin?

Avvallari buni qilish juda murakkab edi, lekin hozirda bir nechta ajoyib dasturlar bor:

1.  **Ollama:** Eng oson usul. Bitta buyruq bilan (`ollama run llama3`) modelni ishga tushirasiz. MacOS, Linux va Windows uchun mavjud.
2.  **LM Studio:** Chiroyli grafik interfeysli dastur. HuggingFace dan modellarni yuklab olish va chat interfeysida tekshirish imkonini beradi.
3.  **vLLM:** Agar sizga serverda ko'p foydalanuvchiga xizmat ko'rsatuvchi yuqori unumdorlik kerak bo'lsa, bu eng yaxshi tanlov.

---

### Talablar (Apparat)

Mahalliy LLMlar uchun eng muhim narsa — bu **VRAM** (video karta xotirasi):
-   **8B parametrli modellar:** Kamida 8-10 GB VRAM yoki 16 GB RAM (Apple M-series) talab qiladi.
-   **70B parametrli modellar:** Kamida 40-48 GB VRAM ( professional GPU) talab qiladi.

**Xulosa:** Mahalliy LLMlar — bu AI ustidan nazoratni foydalanuvchiga qaytarish demakdir. Agar sizda yetarli server quvvati bo'lsa, bu yechim uzoq muddatda eng arzon va xavfsiz yo'ldir.
