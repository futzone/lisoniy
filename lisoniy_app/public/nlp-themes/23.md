# 23-Mavzu: Transformerlar

## Modern NLP ning "Yuragi": Transformer Inqilobi

2017-yilda Google tadqiqotchilari tomondan chiqarilgan **"Attention is All You Need"** (Sizga faqat "Diqqat" kerak) maqolasi NLP olamini butunlay o'zgartirdi. Hozirgi kunda barcha LLMlar (GPT-4, Gemini, Claude) aynan **Transformer** arxitekturasiga asoslangan.

---

### Nima Uchun Transformerlar Inqilob Qildi?

Transformerlardan oldin RNN (Recurrent Neural Networks) modellaridan foydalanilardi. Ular matnni so'zma-so'z, ketma-ket o'qishi kerak edi. Bu ikkita katta muammoni keltirib chiqardi:
1.  **Sekinlik:** Matnni parallel (bir vaqtda) o'qib bo'lmasdi.
2.  **Unutish (Vanishing Gradient):** Gap juda uzun bo'lsa, model gapning boshini unutib qo'yardi.

Transformerlar esa matnning barcha so'zlarini **bir vaqtda** ko'ra oladi va qayta ishlaydi.

---

### Self-Attention (O'z-o'ziga diqqat) Mexanizmi

Bu Transformerning eng asosiy "sehrli" qismidir. U gapdagi har bir so'z boshqa barcha so'zlarga qanchalik "bog'liqligini" (diqqat ajratish kerakligini) aniqlaydi.

**Misol:**
"Sher bu daryoda suv ichdi, chunki **u** chanqagan edi."
Bu gapda **"u"** so'zi kimga tegishli? Transformer o'zining "Attention" mexanizmi orqali "u" so'zining "Sher" so'zi bilan bog'liqlik kuchi balandligini darhol hisoblaydi. Bu modelga matnning ichki strukturasini chuqur tushunish imkonini beradi.

---

### Encoder va Decoder

Transformer arxitekturasi ikki qismdan iborat:
1.  **Encoder (Kodlovchi):** Matnni tushunish va uni boy raqamli ma'lumotga (embedding) aylantirish uchun xizmat qiladi (masalan, BERT modeli).
2.  **Decoder (Dekodlovchi):** Berilgan ma'lumotdan yangi matn (so'zlar) yaratish uchun xizmat qiladi (masalan, GPT modellari).

---

### Ochiq Manbali Transformerlar

Siz Hugging Face kabi platformalardan tayyor Transformer modellarni yuklab olib, o'z ishingizda ishlatishingiz mumkin. Ular matnni tahlil qilish, tarjima qilish, savollarga javob berish va boshqa barcha NLP vazifalarida eng yaxshi natijani beradi.

**Xulosa:** Transformer â€” bu insoniy "diqqat" (attention) jarayonining matematik nusxasidir. U zamonaviy sun'iy intellektning matnli ma'lumotlarni o'rganish tezligi va sifatini minglab marta oshirib yubordi.
