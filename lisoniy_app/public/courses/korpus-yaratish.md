# Korpus Yaratish Bosqichlari

Bu qoâ€˜llanma shunchaki nazariya emas, balki real loyiha (masalan, kichik "Oâ€˜zbek Yangiliklar Korpusi") ustida ishlash uchun yoâ€˜riqnomadir.

---

# ğŸ—ï¸ Korpus Yaratish: Gâ€˜oyadan Tayyor Mahsulotgacha

Oâ€˜z korpusimizni yaratish â€” bu xuddi uy qurishga oâ€˜xshaydi. Agar poydevor (reja) qiyshiq boâ€˜lsa, uy (AI modeli) qulab tushadi. Agar gâ€˜ishtlar (maâ€™lumot) sifatsiz boâ€˜lsa, uy sovuq boâ€˜ladi.

Keling, bu jarayonni 5 ta professional bosqichda koâ€˜rib chiqamiz.

---

## 1-Bosqich: Rejalashtirish (Blueprint) ğŸ“

Kod yozishdan oldin qogâ€˜oz va qalam olib, loyihaning "Pasporti"ni chizib olishimiz kerak.

### Asosiy savollar:
1.  **Maqsad nima?**
    *   *Chatbot uchun:* Bizga savol-javob (dialog) matnlari kerak.
    *   *Grammatik tekshirgich uchun:* Bizga adabiy tildagi "toza" matnlar kerak.
    *   *Sotsiologik tadqiqot:* Ijtimoiy tarmoqlardagi "slang" va jargonlar kerak.
2.  **Hajm (Volume):**
    *   Kichik tadqiqot: 1 mln soâ€˜z.
    *   LLM oâ€˜qitish: 100 mln+ soâ€˜z.
3.  **Balans (Balance):**
    *   Agar korpusning 90% qismi "Sport yangiliklari" boâ€˜lsa, sizning AI modelingiz siyosat haqida soâ€˜rasangiz ham "Futbol" deb javob beradi.
    *   **Yechim:** Kvota belgilash (masalan: 30% Yangilik, 30% Badiiy, 20% Ilmiy, 20% Ogâ€˜zaki).

---

## 2-Bosqich: Maâ€™lumot Yigâ€˜ish (Data Collection) ğŸ•·ï¸

Bu bosqichda biz Internetdagi maâ€™lumotlarni "oâ€˜rib olamiz". Buning uchun **Web Scraping** yoki **Crawling** usullari ishlatiladi.

### Asosiy Manbalar:
1.  **Web Scraping:** `kun.uz`, `gazeta.uz`, `daryo.uz` kabi saytlardan maqolalarni yigâ€˜ish.
2.  **OCR (Optical Character Recognition):** PDF kitoblar yoki gazeta skanlarini (`Tesseract` yordamida) matnga aylantirish.
3.  **API:** Twitter, Telegram yoki Wikipedia API orqali qonuniy ma'lumot olish.

### ğŸ Python Example: Web Scraper
Oddiygina yangilik saytidan sarlavha va matnni koâ€˜chirib oluvchi bot yozamiz.

```python
import requests
from bs4 import BeautifulSoup

def scrape_news(url):
    # 1. Saytga so'rov yuborish (User-Agent muhim, bot ekanligimizni yashiramiz)
    headers = {'User-Agent': 'Mozilla/5.0 (Lisoniy Corpus Bot)'}
    response = requests.get(url, headers=headers)
    
    if response.status_code != 200:
        return None

    # 2. HTMLni parslash
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # 3. Kerakli qismlarni ajratib olish (CSS Selectorlar orqali)
    title = soup.find('h1').get_text(strip=True)
    
    # Maqola matni odatda <p> teglarida bo'ladi
    article_body = " ".join([p.get_text(strip=True) for p in soup.find_all('p')])
    
    return {
        "url": url,
        "title": title,
        "text": article_body
    }

# Ishlatib ko'ramiz (taxminiy URL)
data = scrape_news('https://kun.uz/news/2024/05/21/namuna-maqola')
print(data)
```

---

## 3-Bosqich: Tozalash (Data Cleaning) ğŸ§¹

Internetdan olingan maâ€™lumot har doim "iflos" boâ€˜ladi. Unda HTML kodlar, reklamalar, JavaScript boâ€˜laklari va emojilar aralashib yotadi.
**Qoida:** "Garbage In, Garbage Out" (Axlat kirdi, axlat chiqadi).

### Nimalarni tozalaymiz?
1.  **HTML Teglar:** `<div>`, `<br>`, `&nbsp;`.
2.  **Boilerplate:** "Saytga obuna boâ€˜ling", "Reklama" kabi takrorlanuvchi matnlar.
3.  **Deduplication:** Bir xil maqola 10 ta saytda chiqishi mumkin. Bizga faqat bittasi kerak.

### ğŸ Python Example: Cleaning Pipeline

```python
import re

def clean_text(raw_text):
    # 1. HTML teglarni olib tashlash (<...>)
    text = re.sub(r'<[^>]+>', '', raw_text)
    
    # 2. URL va Email manzillarni o'chirish
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'\S+@\S+', '', text)
    
    # 3. Ortiqcha bo'shliqlarni (whitespace) bittaga keltirish
    # "Salom      dunyo" -> "Salom dunyo"
    text = re.sub(r'\s+', ' ', text).strip()
    
    # 4. Normalizatsiya (Masalan, kirilldagi 'Ò³' va lotindagi 'h' ni birxillashtirish kerak bo'lsa)
    # Bu qism loyiha talabiga qarab yoziladi.
    
    return text

raw_input = "<p>Bugun havo <strong>ajoyib!</strong>   Batafsil: http://kun.uz</p>"
clean_output = clean_text(raw_input)

print(f"Oldin: {raw_input}")
print(f"Keyin: {clean_output}")
# Natija: Bugun havo ajoyib! Batafsil:
```

---

## 4-Bosqich: Annotatsiya (Tagging) ğŸ·ï¸

Endi "toza" matnni "aqlli" matnga aylantiramiz.

### Usullar:
1.  **Avtomatik (NLP Pipeline):** `UzStanza` yoki `Trankit` kabi modellar yordamida butun korpusni bir necha soatda teglab chiqish.
2.  **Manual (Qoâ€˜lda):** Agar siz oltin standart (Gold Standard) korpus tuzayotgan boâ€˜lsangiz, har bir gapni tilshunoslar tekshirib chiqishi shart.

**Annotatsiya nimani oâ€˜z ichiga oladi?**
*   **POS:** Soâ€˜z turkumi.
*   **Lemma:** Soâ€˜z oâ€˜zagi.
*   **Sentence Boundaries:** Gap qayerda tugashini aniq belgilash (bu juda qiyin masala, masalan "A.Q.Sh." soâ€˜zida nuqtalar bor, lekin gap tugamagan).

---

## 5-Bosqich: Saqlash va Tarqatish ğŸ’¾

Korpus tayyor. Endi uni qanday saqlaymiz? Oddiy `.txt` fayl katta hajmdagi qidiruv uchun yaroqsiz.

### Formatlar:
*   **JSONL (JSON Lines):** Har bir qator bitta hujjat. Dasturchilar va LLM oâ€˜qitish uchun eng qulay format.
*   **XML (TEI):** Raqamli gumanitar fanlar va klassik tilshunoslik uchun standart.

### Qidiruv Tizimlari (Indexing):
Foydalanuvchilar korpus ichidan "Ega + Kesim" qolipidagi gaplarni qidira olishi kerak.
1.  **Elasticsearch:** Zamonaviy, tezkor, web-loyihalar uchun (Lisoniy uchun tavsiya etiladi).
2.  **CWB (Corpus Workbench):** Professional lingvistlar uchun maxsus indekslash tizimi.
3.  **Sketch Engine:** Agar byudjet boâ€˜lsa, tayyor platformaga yuklash.

### ğŸ Python Example: Saving to JSONL

```python
import json

corpus_data = [
    {"id": 1, "text": "Salom dunyo", "meta": {"year": 2024}},
    {"id": 2, "text": "Python zo'r til", "meta": {"year": 2023}}
]

# JSONL formatida saqlash (Append mode)
with open('lisoniy_corpus.jsonl', 'w', encoding='utf-8') as f:
    for entry in corpus_data:
        json.dump(entry, f, ensure_ascii=False)
        f.write('\n') # Yangi qator

print("Korpus muvaffaqiyatli saqlandi!")
```

---

## Xulosa

Korpus yaratish â€” bu bir martalik ish emas. Bu **siklik jarayon**.
1.  Yigâ€˜asiz.
2.  Tozalaysiz.
3.  Ishlatib koâ€˜rasiz (Model oâ€˜qitasiz).
4.  Xatolarini koâ€˜rib, yana yangi maâ€™lumot yigâ€˜ishga qaytasiz.

"Lisoniy" platformasi orqali biz bu jarayonni avtomatlashtirib, oâ€˜zbek tili uchun eng katta va sifatli bazani yaratishni maqsad qilganmiz. ğŸš€